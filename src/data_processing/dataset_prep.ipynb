{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import glob\n",
    "import datetime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FULL_LAION_PATH = \"/Users/yavuz/data/part-00000-5b54c5d5-bbcf-484d-a2ce-0d6f73df1a36-c000.snappy.parquet\"\n",
    "\n",
    "ENTITY_COUNT = 10000\n",
    "PREP_DATASET_PATH = \"/Users/yavuz/data/LAION-10000/\"\n",
    "\n",
    "if os.path.exists(PREP_DATASET_PATH):\n",
    "    print(f\"Warning: {PREP_DATASET_PATH} exists!\")\n",
    "else:\n",
    "    os.makedirs(PREP_DATASET_PATH)\n",
    "\n",
    "IMAGES_PATH = PREP_DATASET_PATH + \"images\"\n",
    "URLS_PATH = PREP_DATASET_PATH + \"urls.txt\"\n",
    "SUCCEEDED_URLS_PATH = PREP_DATASET_PATH + \"succeeded-urls.txt\"\n",
    "DATA_PATH = PREP_DATASET_PATH + \"metadata.parquet\""
   ],
   "id": "b16b6e93054551a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_safe_data(path: str, count:int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return non-nsfw entries from the full LAION dataset.\n",
    "    \"\"\"\n",
    "    print(f\"Reading {count} items from full LAION dataset...\")\n",
    "    df = pd.read_parquet(path)[:count]\n",
    "    \n",
    "    nsfw_removed_data = df[df[\"NSFW\"]==\"UNLIKELY\"]\n",
    "    print(\"Size after removing NSFW:\", len(nsfw_removed_data))\n",
    "    \n",
    "    clean_url_data = nsfw_removed_data[~nsfw_removed_data['URL'].str.contains(',')]\n",
    "    print(\"Size after removing URLs with commas:\", len(clean_url_data))\n",
    "\n",
    "    return clean_url_data"
   ],
   "id": "570a0e3ef0036051",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = read_safe_data(FULL_LAION_PATH, ENTITY_COUNT)\n",
    "data"
   ],
   "id": "5b0fb588a10035b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def write_urls(data: pd.DataFrame, path: str) -> None:\n",
    "    \"\"\"\n",
    "    Writes the URLs found in the dataframe to a file in the given path\n",
    "    \"\"\"\n",
    "    with open(path, \"w+\") as f:\n",
    "        for url in data[\"URL\"]:\n",
    "            f.write(url + \"\\n\")\n",
    "    print(f\"Finished writing {len(data)} URLs to {path}\")\n",
    "\n",
    "write_urls(data, URLS_PATH)"
   ],
   "id": "7352514bcdb86df4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def download_images(url_path: str, images_path: str):\n",
    "    \"\"\"\n",
    "    download images from text file with list of urls \n",
    "    \"\"\"\n",
    "    if os.path.exists(images_path):\n",
    "        print(f\"Warning: {images_path} exists - renaming it...!\")\n",
    "        os.rename(IMAGES_PATH, IMAGES_PATH + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "        \n",
    "    subprocess.call([\"img2dataset\", \"--url_list=\"+url_path, \"--output_folder=\"+images_path, \"--thread_count=64\", \"--image_size=256\"])"
   ],
   "id": "e8db576ee4b7e768",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "download_images(URLS_PATH, IMAGES_PATH)",
   "id": "dce90458186e0f60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#get a list of all files in IMAGES_PATH that end with .jpg\n",
    "files = glob.glob(IMAGES_PATH+\"/*/*.jpg\")\n",
    "files = [file.split('/')[-2:] for file in files]\n",
    "len(files)"
   ],
   "id": "7c59cf177a9dff58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ids = [int(file[1].split('.')[0]) for file in files]\n",
    "ids.sort()"
   ],
   "id": "f5fdb8943b44da33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_with_images = data.iloc[ids]\n",
    "data_with_images"
   ],
   "id": "7d34665cb1cd7b11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_with_images.iloc[-1]",
   "id": "ae14126ded7295ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "write_urls(data_with_images, SUCCEEDED_URLS_PATH)\n",
    "#download_images(URLS_PATH, IMAGES_PATH)"
   ],
   "id": "5733e6163b8f031c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save metadata to parquet\n",
    "data_with_images.to_parquet(DATA_PATH)"
   ],
   "id": "cc60c7123f7af2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
