{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import glob\n",
    "from src.embedding_generation.text_embeddings import *\n",
    "from src.common.logger import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b67d5cc4882c1216",
   "metadata": {},
   "source": [
    "#Specify dataset and paths to work on\n",
    "DATASET_ENTITY_COUNT = 100\n",
    "DATASET_BASE_PATH = f\"/Users/yavuz/data/LAION-{DATASET_ENTITY_COUNT}/\"\n",
    "\n",
    "METADATA_PATH = DATASET_BASE_PATH + \"metadata.parquet\"\n",
    "IMAGES_PATH = DATASET_BASE_PATH + \"images/\"\n",
    "\n",
    "vector_path = DATASET_BASE_PATH + \"vectors/\"\n",
    "if not os.path.exists(vector_path):\n",
    "    print(\"Creating path\", vector_path)\n",
    "    os.makedirs(vector_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5a8bbc70d126ff5f",
   "metadata": {},
   "source": [
    "# Text Embedding Generation\n",
    "model = \"BAAI/bge-small-en-v1.5\"\n",
    "df = pd.read_parquet(METADATA_PATH)\n",
    "texts = list(df[\"TEXT\"])\n",
    "embedding_generator: TextEmbeddingGenerator = SentenceTransformerEmbeddingGenerator(model)\n",
    "embeddings = embedding_generator.generate_text_embeddings(texts, True)\n",
    "embeddings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1915a7cd3b7847f",
   "metadata": {},
   "source": [
    "# Save text embeddings\n",
    "np.save(vector_path+\"text_vectors\", embeddings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d1e04fa537b197f",
   "metadata": {},
   "source": [
    "#Test text embedding retrieval and confirm shape\n",
    "read_embeddings = np.load(vector_path+\"text_vectors.npy\")\n",
    "read_embeddings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9f1e138f75539ec",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Image Embedding Generation\n",
    "from src.embedding_generation.image_embeddings import *"
   ],
   "id": "eb7d2295f5786d0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_paths = glob.glob(IMAGES_PATH+\"/*/*.jpg\")\n",
    "image_paths.sort()\n",
    "len(image_paths)"
   ],
   "id": "d3c3f6c154602665",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d16b9dab0c66343a",
   "metadata": {},
   "source": [
    "image_embedding_generator: ImageEmbeddingGenerator = HFImageEmbeddingGenerator(\"google/vit-base-patch16-224-in21k\")\n",
    "image_embeddings = image_embedding_generator.batch_generate_image_embeddings(image_paths, True)\n",
    "image_embeddings.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save image embeddings\n",
    "np.save(vector_path+\"image_vectors\", image_embeddings)"
   ],
   "id": "5fa70161991755e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "258e1a3e0e739dd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify placeholder images by computing similarity across paris of image embeddings\n",
    "# Those with >0.99 are deemed to be placeholder images. \n",
    "# This boundary was chosen using some experimentation and visual inspection of sample images.\n",
    "from IPython.display import display, Image\n",
    "\n",
    "image_embeddings = np.load(vector_path + \"image_vectors.npy\")\n",
    "image_embeddings.shape"
   ],
   "id": "879ffc66a1fb1ae1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_image(vector_id: int, images_path: str):\n",
    "    \"\"\"\n",
    "    Given a vector id and base images path (IMAGES_PATH), returns the image.\n",
    "    \"\"\"\n",
    "    shard = str(vector_id // 10000).zfill(5)\n",
    "    index = str(vector_id % 10000).zfill(4)\n",
    "    image_path = f\"{images_path}/{shard}/{shard}{index}.jpg\"\n",
    "    return Image(filename=image_path) "
   ],
   "id": "da626f8e4686f2c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Normalize embeddings and compute similarity matrix\n",
    "image_embeddings /  np.linalg.norm(image_embeddings, axis=1, keepdims=True)\n",
    "similarity_matrix = np.dot(image_embeddings, image_embeddings.T)"
   ],
   "id": "b7131b6bfb43cd01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "near_duplicates = []\n",
    "for i in range(len(similarity_matrix)):\n",
    "    for j in range(i+1, len(similarity_matrix)):\n",
    "        # 0.99 has been chosen the boundary after some experimentation, by viewing sample images\n",
    "        if similarity_matrix[i][j] > 0.99:\n",
    "            near_duplicates.append((i, j, similarity_matrix[i][j]))\n",
    "near_duplicates.sort(key=lambda x: x[2]) # sort to view sample least similar items\n",
    "len(near_duplicates)"
   ],
   "id": "d5290a3eb52be4ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(get_image(18, IMAGES_PATH))",
   "id": "9a405f92ecf2aa7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# extract ids that are near-duplicates, ordered by similarity\n",
    "near_duplicate_ids = set()\n",
    "for i, j, _ in near_duplicates:\n",
    "    near_duplicate_ids.add(i)\n",
    "    near_duplicate_ids.add(j)\n",
    "near_duplicate_ids"
   ],
   "id": "4bf839449397250f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.save(vector_path+\"placeholder_images\", np.array(list(near_duplicate_ids)))",
   "id": "afb9ede1598ac59e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c3f0b693614de318",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
