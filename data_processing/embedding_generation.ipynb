{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "This script is used to generate and save vector embeddings for the text and image data prepared in dataset_preparation.ipynb. Update the parameters in the cell below. Additionally, the number of threads used to generate text/image embeddings can be amended in their corresponding function calls below. The last part of this notebook identifies placeholder images by computing pairwise similarities across every generated image embedding.\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import glob\n",
    "from src.embedding_generation.text_embeddings import *\n",
    "from src.common.logger import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b67d5cc4882c1216",
   "metadata": {},
   "source": [
    "# specify dataset and paths to work on\n",
    "DATASET_ENTITY_COUNT = 222\n",
    "DATASET_BASE_PATH = f\"/Users/yavuz/data/LAION-{DATASET_ENTITY_COUNT}/\"\n",
    "\n",
    "NUM_VECTORS_TO_GENERATE = None # set to None to generate vectors for all available entities\n",
    "\n",
    "METADATA_PATH = DATASET_BASE_PATH + \"metadata.parquet\"\n",
    "IMAGES_PATH = DATASET_BASE_PATH + \"images/\"\n",
    "\n",
    "vector_path = DATASET_BASE_PATH + \"vectors/\"\n",
    "if not os.path.exists(vector_path):\n",
    "    print(\"Creating path\", vector_path)\n",
    "    os.makedirs(vector_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5a8bbc70d126ff5f",
   "metadata": {},
   "source": [
    "# Text Embedding Generation\n",
    "model = \"BAAI/bge-small-en-v1.5\"\n",
    "df = pd.read_parquet(METADATA_PATH)\n",
    "texts = list(df[\"TEXT\"])\n",
    "if NUM_VECTORS_TO_GENERATE is not None:\n",
    "    texts = texts[:NUM_VECTORS_TO_GENERATE]\n",
    "\n",
    "embedding_generator: TextEmbeddingGenerator = SentenceTransformerEmbeddingGenerator(model)\n",
    "embeddings = embedding_generator.generate_text_embeddings(texts, normalize_embeddings=False, batch_size=128)\n",
    "embeddings.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1915a7cd3b7847f",
   "metadata": {},
   "source": [
    "# save text embeddings\n",
    "# check if path already exists\n",
    "text_vector_path = vector_path+\"text_vectors\"\n",
    "if os.path.exists(text_vector_path + \".npy\"):\n",
    "    new_path = text_vector_path + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    print(f\"Path {text_vector_path} already exists. Instead saving to {new_path}.npy\")\n",
    "    text_vector_path = new_path\n",
    "np.save(text_vector_path, embeddings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d1e04fa537b197f",
   "metadata": {},
   "source": [
    "# test text embeddings retrieval and confirm shape and type\n",
    "read_embeddings = np.load(text_vector_path+\".npy\")\n",
    "read_embeddings.shape, read_embeddings.dtype"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9f1e138f75539ec",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Image Embedding Generation\n",
    "from src.embedding_generation.image_embeddings import *"
   ],
   "id": "eb7d2295f5786d0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_paths = glob.glob(IMAGES_PATH+\"/*/*.jpg\")\n",
    "image_paths.sort()\n",
    "\n",
    "if NUM_VECTORS_TO_GENERATE is not None:\n",
    "    image_paths = image_paths[:NUM_VECTORS_TO_GENERATE]\n",
    "\n",
    "len(image_paths)"
   ],
   "id": "d3c3f6c154602665",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d16b9dab0c66343a",
   "metadata": {},
   "source": [
    "image_embedding_generator: ImageEmbeddingGenerator = HFImageEmbeddingGenerator(\"google/vit-base-patch16-224-in21k\")\n",
    "image_embeddings = image_embedding_generator.batch_generate_image_embeddings(image_paths, normalize_embeddings=False, batch_size=128)\n",
    "image_embeddings.shape, image_embeddings.dtype"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save image embeddings\n",
    "# check if path already exists\n",
    "image_vector_path = vector_path+\"image_vectors\"\n",
    "if os.path.exists(image_vector_path + \".npy\"):\n",
    "    new_path = image_vector_path + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    print(f\"Path {image_vector_path} already exists. Instead saving to {new_path}.npy\")\n",
    "    image_vector_path = new_path\n",
    "\n",
    "np.save(image_vector_path, image_embeddings)"
   ],
   "id": "5fa70161991755e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test image embeddings retrieval and confirm shape and type\n",
    "read_embeddings = np.load(image_vector_path+\".npy\")\n",
    "read_embeddings.shape, read_embeddings.dtype"
   ],
   "id": "2ad2504891e13a13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dec5fc4ae77493ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "read_embeddings[0]",
   "id": "c7a4563ad39fbabb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optional: identify placeholder images. Note: Performance will be slow for large datasets ( O(n^2) ).\n",
    "\n",
    "# Identify placeholder images by computing similarity across pairs of image embeddings\n",
    "# Those with >0.99 are deemed to be placeholder images. \n",
    "# This boundary was chosen using some experimentation and visual inspection of sample images.\n",
    "from IPython.display import display, Image"
   ],
   "id": "879ffc66a1fb1ae1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_embeddings = np.load(vector_path + \"image_vectors.npy\")\n",
    "image_embeddings.shape"
   ],
   "id": "da626f8e4686f2c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "image_embeddings",
   "id": "88f3d5926d14acd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Normalize embeddings and compute similarity matrix\n",
    "normalised_image_embeddings = image_embeddings / np.linalg.norm(image_embeddings, axis=1, keepdims=True)\n",
    "similarity_matrix = np.dot(normalised_image_embeddings, normalised_image_embeddings.T)"
   ],
   "id": "b7131b6bfb43cd01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "similarity_matrix",
   "id": "86684acebd6d80ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "near_duplicates = []\n",
    "for i in range(len(similarity_matrix)):\n",
    "    for j in range(i+1, len(similarity_matrix)):\n",
    "        # 0.99 has been chosen the boundary after some experimentation, by viewing sample images\n",
    "        if similarity_matrix[i][j] > 0.99:\n",
    "            near_duplicates.append((i, j, similarity_matrix[i][j]))\n",
    "near_duplicates.sort(key=lambda x: x[2]) # sort to view sample least similar items\n",
    "len(near_duplicates)"
   ],
   "id": "d5290a3eb52be4ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# extract ids that are near-duplicates, ordered by similarity\n",
    "near_duplicate_ids = set()\n",
    "for i, j, _ in near_duplicates:\n",
    "    near_duplicate_ids.add(i)\n",
    "    near_duplicate_ids.add(j)\n",
    "near_duplicate_ids"
   ],
   "id": "4bf839449397250f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.save(vector_path+\"placeholder_images\", np.array(list(near_duplicate_ids)))",
   "id": "afb9ede1598ac59e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "placeholder_images = np.load(vector_path+\"placeholder_images.npy\")\n",
    "# there are 164 images identified in 20k dataset\n",
    "# there are 5-10 images which are not placeholder, but are identified because exact duplicates exist in the dataset\n",
    "placeholder_images.shape"
   ],
   "id": "c3f0b693614de318",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_image(vector_id: int, images_path: str):\n",
    "    \"\"\"\n",
    "    Given a vector id and base images path (IMAGES_PATH), returns the image.\n",
    "    \"\"\"\n",
    "    shard = str(vector_id // 10000).zfill(5)\n",
    "    index = str(vector_id % 10000).zfill(4)\n",
    "    image_path = f\"{images_path}/{shard}/{shard}{index}.jpg\"\n",
    "    return Image(filename=image_path) "
   ],
   "id": "60614de78a6ab74f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print sample placeholder images\n",
    "LIMIT = 10\n",
    "for i in placeholder_images[:LIMIT]:\n",
    "    print(i)\n",
    "    display(get_image(i, IMAGES_PATH))"
   ],
   "id": "cab670c21aec9c07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "963c870874c6fd8a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
